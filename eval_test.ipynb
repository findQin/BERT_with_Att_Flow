{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import collections, time, spacy, copy, string, re\n","from layers.bert_plus_bidaf import BERT_plus_BiDAF\n","from utils import data_processing\n","from torch.utils.data import DataLoader\n","from transformers import BertTokenizerFast"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["val_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\"\n","val_encodings, val_answer = data_processing.data_processing(val_url)\n","torch.save(val_answer,r'D:\\OneDrive\\Courses\\ECS289 NLP\\val_answer.pt')\n","torch.save(val_encodings,r'D:\\OneDrive\\Courses\\ECS289 NLP\\val_encodings.pt')"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["val_encodings = torch.load(r'D:\\OneDrive\\Courses\\ECS289 NLP\\val_encodings.pt')\n","val_answer=torch.load(r'D:\\OneDrive\\Courses\\ECS289 NLP\\val_answer.pt')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class SquadDataset(torch.utils.data.Dataset):\n","  def __init__(self,encodings):\n","    self.encodings = encodings\n","  def __getitem__(self,idx):\n","    return {key:torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","  def __len__(self):\n","    return len(self.encodings.input_ids)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["val_dataset = SquadDataset(val_encodings)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Model imported successfully\n"]}],"source":["model = BERT_plus_BiDAF(if_extra_modeling=True)\n","model.load_state_dict(torch.load(r'D:\\OneDrive\\Courses\\ECS289 NLP\\bert_BiDAF.pt'))\n","model = model.to(device)\n","print(\"Model imported successfully\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","def predict(logits_start, logits_end, threshold = 0.1):\n","    \"\"\"\n","    Input:\n","    logits_start, logits_end: torch.tensor() of shape [batch_size, sequence length]\n","    return the index i,j such that i<=j and logits_start[i]+logits[j] is maximized\n","    \"\"\"\n","    # compute probability\n","    p_start = F.softmax(logits_start, dim=-1)\n","    p_end = F.softmax(logits_end, dim=-1)\n","    # compute joint probability\n","    p_joint = torch.triu(torch.bmm(p_start.unsqueeze(dim=2), p_end.unsqueeze(dim=1)))\n","    # get the batchwise indices\n","    max_row, _ = torch.max(p_joint, dim=2)\n","    max_col, _ = torch.max(p_joint, dim=1)\n","    start = torch.argmax(max_row, dim=-1)\n","    end = torch.argmax(max_col, dim=-1)\n","    # check if indices are greater than no answer probability by threshold\n","    p_na = p_joint[:,0,0]\n","    max_prob,_ = torch.max(max_row,dim=-1)\n","    start[p_na + threshold > max_prob] = 0\n","    end[p_na + threshold > max_prob] = 0\n","    return start, end"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def normalize_answer(s):\n","    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n","    def remove_articles(text):\n","        regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n","        return re.sub(regex, ' ', text)\n","    def white_space_fix(text):\n","        return ' '.join(text.split())\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return ''.join(ch for ch in text if ch not in exclude)\n","    def lower(text):\n","        return text.lower()\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["nlp = spacy.blank(\"en\")\n","def word_tokenize(sent):\n","    doc = nlp(sent)\n","    return [token.text for token in doc]"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def compute_f1(a_gold, a_pred):\n","    gold_toks = word_tokenize(a_gold)\n","    pred_toks = word_tokenize(a_pred)\n","    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n","    num_same = sum(common.values())\n","    if len(gold_toks) == 0 or len(pred_toks) == 0:\n","        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n","        return int(gold_toks == pred_toks)\n","    if num_same == 0:\n","        return 0\n","    precision = 1.0 * num_same / len(pred_toks)\n","    recall = 1.0 * num_same / len(gold_toks)\n","    f1 = (2 * precision * recall) / (precision + recall)\n","    return f1"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def evaluate(model, eval_dataset, answers, threshold=0.1):\n","    \"\"\" TODO: debug\"\"\"\n","    n = len(eval_dataset)\n","    exact_match = 0\n","    f1_sum = 0\n","    model.eval()\n","    with torch.no_grad():\n","        for i in range(n):\n","            if i%1000==0:\n","                print('evaluated {}/{}:'.format(i, n))\n","            input_ids = eval_dataset[i]['input_ids']\n","            attention_mask = eval_dataset[i]['attention_mask']\n","            golden_answer = normalize_answer(answers[i]['text'])\n","            ipid = torch.unsqueeze(input_ids,0)\n","            attm = torch.unsqueeze(attention_mask,0)\n","            with torch.cuda.device(0):\n","                ipid = ipid.cuda(non_blocking=True)  # in test loader, pin_memory = True\n","                attm = attm.cuda(non_blocking=True)\n","            _, start_logits, end_logits = model(ipid, attm)\n","\n","            # compute null score and make prediction:\n","            start, end = predict(torch.unsqueeze(start_logits,dim=0),torch.unsqueeze(end_logits,dim=0), threshold)\n","            # adjust to the context padding\n","            start[start!=0] += 62\n","            end[end!=0] += 62\n","            if (i%250 == 0):\n","                print(\"sample \",i,': ', start, end)\n","                print(\"true \", i, ': ', eval_dataset[i]['start_positions'], eval_dataset[i]['end_positions'])\n","            if start == 0 and end == 0:\n","                prediction = \"no-answer\"\n","            else:\n","                tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","                prediction = ' '.join(tokens[start:end + 1])\n","\n","                # exact match\n","            if (prediction == golden_answer):\n","                exact_match = exact_match + 1\n","                # F1_score\n","            f1_sum = f1_sum + compute_f1(golden_answer, prediction)\n","    accuracy = exact_match / n\n","    f1 = f1_sum / n\n","    return accuracy, f1"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["evaluated 0/11873:\n","sample  0 :  tensor([103], device='cuda:0') tensor([103], device='cuda:0')\n","true  0 :  tensor(103) tensor(103)\n","sample  250 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  250 :  tensor(0) tensor(0)\n","sample  500 :  tensor([178], device='cuda:0') tensor([179], device='cuda:0')\n","true  500 :  tensor(152) tensor(153)\n","sample  750 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  750 :  tensor(193) tensor(194)\n","evaluated 1000/11873:\n","sample  1000 :  tensor([0], device='cuda:0') tensor([110], device='cuda:0')\n","true  1000 :  tensor(109) tensor(110)\n","sample  1250 :  tensor([91], device='cuda:0') tensor([96], device='cuda:0')\n","true  1250 :  tensor(91) tensor(92)\n","sample  1500 :  tensor([115], device='cuda:0') tensor([121], device='cuda:0')\n","true  1500 :  tensor(0) tensor(0)\n","sample  1750 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  1750 :  tensor(0) tensor(0)\n","evaluated 2000/11873:\n","sample  2000 :  tensor([74], device='cuda:0') tensor([77], device='cuda:0')\n","true  2000 :  tensor(0) tensor(0)\n","sample  2250 :  tensor([73], device='cuda:0') tensor([73], device='cuda:0')\n","true  2250 :  tensor(0) tensor(0)\n","sample  2500 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  2500 :  tensor(0) tensor(0)\n","sample  2750 :  tensor([117], device='cuda:0') tensor([117], device='cuda:0')\n","true  2750 :  tensor(117) tensor(117)\n","evaluated 3000/11873:\n","sample  3000 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  3000 :  tensor(0) tensor(0)\n","sample  3250 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  3250 :  tensor(0) tensor(0)\n","sample  3500 :  tensor([101], device='cuda:0') tensor([107], device='cuda:0')\n","true  3500 :  tensor(101) tensor(107)\n","sample  3750 :  tensor([122], device='cuda:0') tensor([122], device='cuda:0')\n","true  3750 :  tensor(0) tensor(0)\n","evaluated 4000/11873:\n","sample  4000 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  4000 :  tensor(0) tensor(0)\n","sample  4250 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  4250 :  tensor(72) tensor(82)\n","sample  4500 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  4500 :  tensor(0) tensor(0)\n","sample  4750 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  4750 :  tensor(139) tensor(151)\n","evaluated 5000/11873:\n","sample  5000 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  5000 :  tensor(0) tensor(0)\n","sample  5250 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  5250 :  tensor(0) tensor(0)\n","sample  5500 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  5500 :  tensor(126) tensor(130)\n","sample  5750 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  5750 :  tensor(230) tensor(233)\n","evaluated 6000/11873:\n","sample  6000 :  tensor([185], device='cuda:0') tensor([196], device='cuda:0')\n","true  6000 :  tensor(185) tensor(196)\n","sample  6250 :  tensor([205], device='cuda:0') tensor([208], device='cuda:0')\n","true  6250 :  tensor(205) tensor(208)\n","sample  6500 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  6500 :  tensor(0) tensor(0)\n","sample  6750 :  tensor([83], device='cuda:0') tensor([88], device='cuda:0')\n","true  6750 :  tensor(84) tensor(88)\n","evaluated 7000/11873:\n","sample  7000 :  tensor([109], device='cuda:0') tensor([111], device='cuda:0')\n","true  7000 :  tensor(109) tensor(111)\n","sample  7250 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  7250 :  tensor(186) tensor(189)\n","sample  7500 :  tensor([133], device='cuda:0') tensor([179], device='cuda:0')\n","true  7500 :  tensor(133) tensor(136)\n","sample  7750 :  tensor([0], device='cuda:0') tensor([143], device='cuda:0')\n","true  7750 :  tensor(140) tensor(143)\n","evaluated 8000/11873:\n","sample  8000 :  tensor([120], device='cuda:0') tensor([126], device='cuda:0')\n","true  8000 :  tensor(119) tensor(126)\n","sample  8250 :  tensor([174], device='cuda:0') tensor([181], device='cuda:0')\n","true  8250 :  tensor(0) tensor(0)\n","sample  8500 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  8500 :  tensor(0) tensor(0)\n","sample  8750 :  tensor([166], device='cuda:0') tensor([172], device='cuda:0')\n","true  8750 :  tensor(166) tensor(172)\n","evaluated 9000/11873:\n","sample  9000 :  tensor([75], device='cuda:0') tensor([78], device='cuda:0')\n","true  9000 :  tensor(0) tensor(0)\n","sample  9250 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  9250 :  tensor(171) tensor(172)\n","sample  9500 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  9500 :  tensor(0) tensor(0)\n","sample  9750 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  9750 :  tensor(0) tensor(0)\n","evaluated 10000/11873:\n","sample  10000 :  tensor([103], device='cuda:0') tensor([109], device='cuda:0')\n","true  10000 :  tensor(99) tensor(109)\n","sample  10250 :  tensor([164], device='cuda:0') tensor([164], device='cuda:0')\n","true  10250 :  tensor(0) tensor(0)\n","sample  10500 :  tensor([199], device='cuda:0') tensor([201], device='cuda:0')\n","true  10500 :  tensor(199) tensor(201)\n","sample  10750 :  tensor([129], device='cuda:0') tensor([131], device='cuda:0')\n","true  10750 :  tensor(129) tensor(130)\n","evaluated 11000/11873:\n","sample  11000 :  tensor([0], device='cuda:0') tensor([69], device='cuda:0')\n","true  11000 :  tensor(0) tensor(0)\n","sample  11250 :  tensor([69], device='cuda:0') tensor([74], device='cuda:0')\n","true  11250 :  tensor(69) tensor(74)\n","sample  11500 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  11500 :  tensor(204) tensor(204)\n","sample  11750 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","true  11750 :  tensor(0) tensor(0)\n","accuracy: \n","0.11707234902720458\n","f1 score: \n","0.20400848925392415\n"]}],"source":["em, f1 = evaluate(model, val_dataset, val_answer, threshold=-0.05)\n","\n","print(\"accuracy: \")\n","print(em)\n","print(\"f1 score: \")\n","print(f1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2-final"},"orig_nbformat":2,"kernelspec":{"name":"python37264bit1bb203151fa44170a7fa3120ee13b827","display_name":"Python 3.7.2 64-bit"}}}