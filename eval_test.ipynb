{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import collections, time, spacy, copy\n","from layers.bert_plus_bidaf import BERT_plus_BiDAF\n","from utils import data_processing\n","from torch.utils.data import DataLoader\n","from transformers import BertTokenizerFast"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["val_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\"\n","val_encodings, val_answer = data_processing.data_processing(val_url)\n","torch.save(val_answer,r'D:\\OneDrive\\Courses\\ECS289 NLP\\val_answer.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# val_encodings = torch.load(r'D:\\OneDrive\\Courses\\ECS289 NLP\\val_encodings.pt')\n","# val_answer=torch.load(r''D:\\OneDrive\\Courses\\ECS289 NLP\\val_answer.pt'')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["class SquadDataset(torch.utils.data.Dataset):\n","  def __init__(self,encodings):\n","    self.encodings = encodings\n","  def __getitem__(self,idx):\n","    return {key:torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","  def __len__(self):\n","    return len(self.encodings.input_ids)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["val_dataset = SquadDataset(val_encodings)\n","# This part should be model construction."]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Model imported successfully\n"]}],"source":["model = BERT_plus_BiDAF(if_extra_modeling=True)\n","model.load_state_dict(torch.load(r'D:\\OneDrive\\Courses\\ECS289 NLP\\BERT_model'))\n","model = model.to(device)\n","print(\"Model imported successfully\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","def predict(logits_start, logits_end, threshold = 0.1):\n","    \"\"\"\n","    Input:\n","    logits_start, logits_end: torch.tensor() of shape [batch_size, sequence length]\n","    return the index i,j such that i<=j and logits_start[i]+logits[j] is maximized\n","    \"\"\"\n","    # compute probability\n","    p_start = F.softmax(logits_start, dim=-1)\n","    p_end = F.softmax(logits_end, dim=-1)\n","    # compute joint probability\n","    p_joint = torch.triu(torch.bmm(p_start.unsqueeze(dim=2), p_end.unsqueeze(dim=1)))\n","    # get the batchwise indices\n","    max_row, _ = torch.max(p_joint, dim=2)\n","    max_col, _ = torch.max(p_joint, dim=1)\n","    start = torch.argmax(max_row, dim=-1)\n","    end = torch.argmax(max_col, dim=-1)\n","    # check if indices are greater than no answer probability by threshold\n","    p_na = p_joint[:,0,0]\n","    max_prob,_ = torch.max(max_row,dim=-1)\n","    start[p_na + threshold > max_prob] = 0\n","    end[p_na + threshold > max_prob] = 0\n","    return start, end"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["nlp = spacy.blank(\"en\")\n","def word_tokenize(sent):\n","    doc = nlp(sent)\n","    return [token.text for token in doc]"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def compute_f1(a_gold, a_pred):\n","    gold_toks = word_tokenize(a_gold)\n","    pred_toks = word_tokenize(a_pred)\n","    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n","    num_same = sum(common.values())\n","    if len(gold_toks) == 0 or len(pred_toks) == 0:\n","        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n","        return int(gold_toks == pred_toks)\n","    if num_same == 0:\n","        return 0\n","    precision = 1.0 * num_same / len(pred_toks)\n","    recall = 1.0 * num_same / len(gold_toks)\n","    f1 = (2 * precision * recall) / (precision + recall)\n","    return f1"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["def evaluate(model, eval_dataset, answers, threshold=0.1):\n","    \"\"\" TODO: debug\"\"\"\n","    n = len(eval_dataset)\n","    exact_match = 0\n","    f1_sum = 0\n","    model.eval()\n","    with torch.no_grad():\n","        for i in range(100):\n","            if i%1000==0:\n","                print('evaluated {}/{}:'.format(i, n))\n","            input_ids = eval_dataset[i]['input_ids']\n","            attention_mask = eval_dataset[i]['attention_mask']\n","            golden_answer = answers[i]['text']\n","            ipid = torch.unsqueeze(input_ids,0)\n","            attm = torch.unsqueeze(attention_mask,0)\n","            with torch.cuda.device(0):\n","                ipid = ipid.cuda(non_blocking=True)  # in test loader, pin_memory = True\n","                attm = attm.cuda(non_blocking=True)\n","            _, start_logits, end_logits = model(ipid, attm)\n","\n","            # compute null score and make prediction:\n","            start, end = predict(torch.unsqueeze(start_logits,dim=0),torch.unsqueeze(end_logits,dim=0), threshold)\n","            # adjust to the context padding\n","            start[start!=0] += 63\n","            end[end!=0] += 63\n","            print(\"sample \",i,': ', start, end)\n","            if start == 0 and end == 0:\n","                prediction = \"\"\n","            else:\n","                tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","                prediction = ' '.join(tokens[start:end + 1])\n","\n","                # exact match\n","            if (prediction == golden_answer):\n","                exact_match = exact_match + 1\n","                # F1_score\n","            f1_sum = f1_sum + compute_f1(golden_answer, prediction)\n","    accuracy = exact_match / n\n","    f1 = f1_sum / n\n","    return accuracy, f1"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["evaluated 0/11873:\n","sample  0 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  1 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  2 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  3 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  4 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  5 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  6 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  7 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  8 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  9 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  10 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  11 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  12 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  13 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  14 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  15 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  16 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  17 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  18 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  19 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  20 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  21 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  22 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  23 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  24 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  25 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  26 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  27 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  28 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  29 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  30 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  31 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  32 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  33 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  34 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  35 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  36 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  37 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  38 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  39 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  40 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  41 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  42 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  43 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  44 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  45 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  46 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  47 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  48 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  49 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  50 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  51 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  52 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  53 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  54 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  55 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  56 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  57 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  58 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  59 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  60 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  61 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  62 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  63 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  64 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  65 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  66 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  67 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  68 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  69 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  70 :  tensor([183], device='cuda:0') tensor([183], device='cuda:0')\n","sample  71 :  tensor([183], device='cuda:0') tensor([183], device='cuda:0')\n","sample  72 :  tensor([183], device='cuda:0') tensor([183], device='cuda:0')\n","sample  73 :  tensor([183], device='cuda:0') tensor([183], device='cuda:0')\n","sample  74 :  tensor([183], device='cuda:0') tensor([183], device='cuda:0')\n","sample  75 :  tensor([183], device='cuda:0') tensor([183], device='cuda:0')\n","sample  76 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  77 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  78 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  79 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  80 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  81 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  82 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  83 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  84 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  85 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  86 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  87 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  88 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  89 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  90 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  91 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  92 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  93 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  94 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  95 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  96 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  97 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  98 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","sample  99 :  tensor([0], device='cuda:0') tensor([0], device='cuda:0')\n","accuracy: \n","0.0\n","f1 score: \n","0.0\n"]}],"source":["em, f1 = evaluate(model, val_dataset, val_answer)\n","\n","print(\"accuracy: \")\n","print(em)\n","print(\"f1 score: \")\n","print(f1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2-final"},"orig_nbformat":2,"kernelspec":{"name":"python37264bit1bb203151fa44170a7fa3120ee13b827","display_name":"Python 3.7.2 64-bit"}}}